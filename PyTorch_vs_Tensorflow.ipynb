{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsP76ESK1FjOVr5Qf8agV5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/D1emonk/My-repo/blob/dev/PyTorch_vs_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> PyTorch"
      ],
      "metadata": {
        "id": "Hzzy3Jxo7KfS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подходит для быстрого создания прототипов и экспериментов благодаря своей гибкости и динамическим графам вычислений"
      ],
      "metadata": {
        "id": "ZV-9puOE7Fmc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "d8kRCMMy6Tu8",
        "outputId": "de750aeb-7dd9-4203-fbd3-3a2b9197efb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.9754553437232971\n",
            "Epoch 2, Loss: 0.9675039052963257\n",
            "Epoch 3, Loss: 0.963125467300415\n",
            "Epoch 4, Loss: 0.9606351256370544\n",
            "Epoch 5, Loss: 0.9591431617736816\n",
            "Epoch 6, Loss: 0.9581794142723083\n",
            "Epoch 7, Loss: 0.9574958086013794\n",
            "Epoch 8, Loss: 0.9569609761238098\n",
            "Epoch 9, Loss: 0.9565058946609497\n",
            "Epoch 10, Loss: 0.9560937285423279\n",
            "Epoch 11, Loss: 0.9557054042816162\n",
            "Epoch 12, Loss: 0.955330491065979\n",
            "Epoch 13, Loss: 0.9549636244773865\n",
            "Epoch 14, Loss: 0.9546018838882446\n",
            "Epoch 15, Loss: 0.9542438387870789\n",
            "Epoch 16, Loss: 0.9538887143135071\n",
            "Epoch 17, Loss: 0.9535359144210815\n",
            "Epoch 18, Loss: 0.9531855583190918\n",
            "Epoch 19, Loss: 0.9528370499610901\n",
            "Epoch 20, Loss: 0.9524906277656555\n",
            "Epoch 21, Loss: 0.952146053314209\n",
            "Epoch 22, Loss: 0.9518035650253296\n",
            "Epoch 23, Loss: 0.9514628648757935\n",
            "Epoch 24, Loss: 0.9511239528656006\n",
            "Epoch 25, Loss: 0.9507869482040405\n",
            "Epoch 26, Loss: 0.9504519104957581\n",
            "Epoch 27, Loss: 0.9501186609268188\n",
            "Epoch 28, Loss: 0.9497871398925781\n",
            "Epoch 29, Loss: 0.9494574666023254\n",
            "Epoch 30, Loss: 0.9491296410560608\n",
            "Epoch 31, Loss: 0.9488035440444946\n",
            "Epoch 32, Loss: 0.948479175567627\n",
            "Epoch 33, Loss: 0.9481565952301025\n",
            "Epoch 34, Loss: 0.9478357434272766\n",
            "Epoch 35, Loss: 0.947516679763794\n",
            "Epoch 36, Loss: 0.9471993446350098\n",
            "Epoch 37, Loss: 0.9468836188316345\n",
            "Epoch 38, Loss: 0.9465696811676025\n",
            "Epoch 39, Loss: 0.9462573528289795\n",
            "Epoch 40, Loss: 0.9459466338157654\n",
            "Epoch 41, Loss: 0.9456378221511841\n",
            "Epoch 42, Loss: 0.9453304409980774\n",
            "Epoch 43, Loss: 0.945024847984314\n",
            "Epoch 44, Loss: 0.9447208642959595\n",
            "Epoch 45, Loss: 0.9444184899330139\n",
            "Epoch 46, Loss: 0.9441176056861877\n",
            "Epoch 47, Loss: 0.9438184499740601\n",
            "Epoch 48, Loss: 0.9435207843780518\n",
            "Epoch 49, Loss: 0.9432247877120972\n",
            "Epoch 50, Loss: 0.942930281162262\n",
            "Epoch 51, Loss: 0.9426373243331909\n",
            "Epoch 52, Loss: 0.9423459768295288\n",
            "Epoch 53, Loss: 0.9420561790466309\n",
            "Epoch 54, Loss: 0.9417678713798523\n",
            "Epoch 55, Loss: 0.9414809942245483\n",
            "Epoch 56, Loss: 0.9411957263946533\n",
            "Epoch 57, Loss: 0.9409120082855225\n",
            "Epoch 58, Loss: 0.940629780292511\n",
            "Epoch 59, Loss: 0.9403489828109741\n",
            "Epoch 60, Loss: 0.9400696754455566\n",
            "Epoch 61, Loss: 0.9397916197776794\n",
            "Epoch 62, Loss: 0.9395151734352112\n",
            "Epoch 63, Loss: 0.9392402172088623\n",
            "Epoch 64, Loss: 0.938966691493988\n",
            "Epoch 65, Loss: 0.9386945366859436\n",
            "Epoch 66, Loss: 0.938423752784729\n",
            "Epoch 67, Loss: 0.9381544589996338\n",
            "Epoch 68, Loss: 0.9378865957260132\n",
            "Epoch 69, Loss: 0.9376199841499329\n",
            "Epoch 70, Loss: 0.9373547434806824\n",
            "Epoch 71, Loss: 0.9370909929275513\n",
            "Epoch 72, Loss: 0.9368285536766052\n",
            "Epoch 73, Loss: 0.9365675449371338\n",
            "Epoch 74, Loss: 0.9363076686859131\n",
            "Epoch 75, Loss: 0.936049222946167\n",
            "Epoch 76, Loss: 0.9357922077178955\n",
            "Epoch 77, Loss: 0.9355365037918091\n",
            "Epoch 78, Loss: 0.9352819919586182\n",
            "Epoch 79, Loss: 0.9350288510322571\n",
            "Epoch 80, Loss: 0.9347770810127258\n",
            "Epoch 81, Loss: 0.9345264434814453\n",
            "Epoch 82, Loss: 0.9342771768569946\n",
            "Epoch 83, Loss: 0.934029221534729\n",
            "Epoch 84, Loss: 0.9337825179100037\n",
            "Epoch 85, Loss: 0.9335368871688843\n",
            "Epoch 86, Loss: 0.9332926869392395\n",
            "Epoch 87, Loss: 0.9330497980117798\n",
            "Epoch 88, Loss: 0.932807981967926\n",
            "Epoch 89, Loss: 0.9325675368309021\n",
            "Epoch 90, Loss: 0.9323281049728394\n",
            "Epoch 91, Loss: 0.9320899844169617\n",
            "Epoch 92, Loss: 0.9318530559539795\n",
            "Epoch 93, Loss: 0.9316174983978271\n",
            "Epoch 94, Loss: 0.931382954120636\n",
            "Epoch 95, Loss: 0.9311496019363403\n",
            "Epoch 96, Loss: 0.9309174418449402\n",
            "Epoch 97, Loss: 0.930686354637146\n",
            "Epoch 98, Loss: 0.9304566979408264\n",
            "Epoch 99, Loss: 0.9302279949188232\n",
            "Epoch 100, Loss: 0.9300004839897156\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Определение модели\n",
        "class DynamicModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DynamicModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(10, 50)\n",
        "        self.fc2 = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Динамический выбор активации\n",
        "        if x.mean() > 0:  # Условие, которое может меняться\n",
        "            x = torch.relu(self.fc1(x))  # ReLU активация\n",
        "        else:\n",
        "            x = torch.sigmoid(self.fc1(x))  # Sigmoid активация\n",
        "        return self.fc2(x)\n",
        "\n",
        "# Создание данных\n",
        "x = torch.randn(100, 10)\n",
        "y = torch.randn(100, 1)\n",
        "\n",
        "# Модель, функция потерь и оптимизатор\n",
        "model = DynamicModel()\n",
        "criterion = nn.MSELoss()  # Среднеквадратичная ошибка\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Обучение\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(x)\n",
        "    loss = criterion(outputs, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель BERT"
      ],
      "metadata": {
        "id": "mrRuOkWe7dz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Загрузка предобученной модели и токенизатора\n",
        "\"BertForSequenceClassification используется для задач классификации текста\"\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Подготовка данных\n",
        "inputs = tokenizer(\"Hello, how are you?\", return_tensors=\"pt\")\n",
        "\n",
        "# Предсказание\n",
        "outputs = model(**inputs)\n",
        "logits = outputs.logits\n",
        "print(logits)\n",
        "\n",
        "# Интерпретация логитов через функцию активации softmax\n",
        "logits = torch.tensor([[0.5625, -0.0854]])\n",
        "probabilities = F.softmax(logits, dim=-1)\n",
        "print(probabilities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VGQPH3O7dYT",
        "outputId": "fa7457d7-3576-4e94-fd30-41afada92315"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0991,  0.0104]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.6565, 0.3435]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> TensorFlow"
      ],
      "metadata": {
        "id": "M1ah5xdW8Bue"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tUm_wDcWdXMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Создание модели\n",
        "model = models.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(10,)),\n",
        "    layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Компиляция модели\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Создание данных\n",
        "x = tf.random.normal((100, 10))\n",
        "y = tf.random.normal((100, 1))\n",
        "\n",
        "# Обучение модели\n",
        "model.fit(x, y, epochs=10)\n",
        "\n",
        "# Сохранение модели для production\n",
        "model.save('my_model.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc-9M5medX0f",
        "outputId": "5cedf677-f8b5-42eb-f8f0-afdf68111d7f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - loss: 1.2168\n",
            "Epoch 2/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2106 \n",
            "Epoch 3/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0654\n",
            "Epoch 4/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0699\n",
            "Epoch 5/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.8529\n",
            "Epoch 6/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9324\n",
            "Epoch 7/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7989\n",
            "Epoch 8/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8228\n",
            "Epoch 9/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8170\n",
            "Epoch 10/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7673\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorFlow Lite позволяет развертывать модели на мобильных устройствах."
      ],
      "metadata": {
        "id": "M67pGKhw8EY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Загрузка сохраненной модели\n",
        "model = tf.keras.models.load_model('my_model.keras')\n",
        "\n",
        "# Конвертация в формат TensorFlow Lite (IOS и Android)\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Сохранение модели\n",
        "with open('model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZHPcRiu71jx",
        "outputId": "81bdf49e-e37f-442e-9acc-958618c365e0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpxp30fq8f'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 10), dtype=tf.float32, name='input_layer_2')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  137128005953360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137128005951440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137127994197200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137127994198160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorFlow имеет мощные инструменты для распределенного обучения на нескольких GPU или узлах."
      ],
      "metadata": {
        "id": "FMEnA4bEcE9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Определение стратегии распределенного обучения\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "# Создание модели внутри стратегии\n",
        "with strategy.scope():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(64, activation='relu', input_shape=(10,)),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Данные\n",
        "x = tf.random.normal((1000, 10))\n",
        "y = tf.random.normal((1000, 1))\n",
        "\n",
        "# Обучение\n",
        "model.fit(x, y, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNG4wQXicFYR",
        "outputId": "0505add4-59e0-4617-81ba-f9d12958ffee"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 1.0885\n",
            "Epoch 2/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.9514\n",
            "Epoch 3/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.8891\n",
            "Epoch 4/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.8974\n",
            "Epoch 5/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8896\n",
            "Epoch 6/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8586\n",
            "Epoch 7/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8680\n",
            "Epoch 8/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8513\n",
            "Epoch 9/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8638\n",
            "Epoch 10/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7756\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7cb79863e990>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}