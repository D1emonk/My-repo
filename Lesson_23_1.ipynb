{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc99a1b4-cb1c-4d47-974c-9ff94e21d68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.2.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in d:\\anaconda\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in d:\\anaconda\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\anaconda\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\anaconda\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\anaconda\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\anaconda\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.71.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.9.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in d:\\anaconda\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in d:\\anaconda\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\anaconda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in d:\\anaconda\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.14.1-cp312-cp312-win_amd64.whl.metadata (50 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\anaconda\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\anaconda\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\anaconda\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\anaconda\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\anaconda\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\anaconda\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl (376.0 MB)\n",
      "   ---------------------------------------- 0.0/376.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/376.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.4/376.0 MB 11.2 MB/s eta 0:00:34\n",
      "   - -------------------------------------- 11.3/376.0 MB 22.7 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 20.4/376.0 MB 29.4 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 31.7/376.0 MB 35.3 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 43.8/376.0 MB 39.2 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 58.2/376.0 MB 43.6 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 74.4/376.0 MB 48.5 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 91.8/376.0 MB 52.8 MB/s eta 0:00:06\n",
      "   ----------- --------------------------- 111.1/376.0 MB 56.8 MB/s eta 0:00:05\n",
      "   ------------- ------------------------- 133.7/376.0 MB 62.4 MB/s eta 0:00:04\n",
      "   ---------------- ---------------------- 157.3/376.0 MB 66.6 MB/s eta 0:00:04\n",
      "   ----------------- --------------------- 172.0/376.0 MB 69.1 MB/s eta 0:00:03\n",
      "   ------------------- ------------------- 190.6/376.0 MB 68.4 MB/s eta 0:00:03\n",
      "   --------------------- ----------------- 212.1/376.0 MB 71.0 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 233.6/376.0 MB 73.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 254.5/376.0 MB 75.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 276.3/376.0 MB 86.4 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 289.4/376.0 MB 87.8 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 305.9/376.0 MB 90.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 320.3/376.0 MB 90.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 331.6/376.0 MB 88.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 342.9/376.0 MB 86.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 353.4/376.0 MB 84.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 364.9/376.0 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 79.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 79.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 79.5 MB/s eta 0:00:01\n",
      "   --------------------------------------- 376.0/376.0 MB 69.5 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.2.0-py3-none-any.whl (276 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.71.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.3/4.3 MB 51.4 MB/s eta 0:00:00\n",
      "Downloading keras-3.9.0-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/1.3 MB 34.8 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 9.7/26.4 MB 50.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 21.2/26.4 MB 53.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 49.3 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl (210 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 5.5/5.5 MB 41.9 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.14.1-cp312-cp312-win_amd64.whl (306 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt-einsum, ml-dtypes, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "Successfully installed absl-py-2.2.0 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 keras-3.9.0 libclang-18.1.1 ml-dtypes-0.5.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.14.1 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 termcolor-2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c9390ec2-2233-45af-9774-f5fccc5c27fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80231a00-2035-4aff-810f-919bcf3a4af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\user\\\\Downloads\\\\ParisHousing.csv', encoding='ISO-8859-1', low_memory=False)\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c49b0146-7036-4331-8fc8-333554b3ae58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>squareMeters</th>\n",
       "      <th>numberOfRooms</th>\n",
       "      <th>hasYard</th>\n",
       "      <th>hasPool</th>\n",
       "      <th>floors</th>\n",
       "      <th>cityCode</th>\n",
       "      <th>cityPartRange</th>\n",
       "      <th>numPrevOwners</th>\n",
       "      <th>made</th>\n",
       "      <th>isNewBuilt</th>\n",
       "      <th>hasStormProtector</th>\n",
       "      <th>basement</th>\n",
       "      <th>attic</th>\n",
       "      <th>garage</th>\n",
       "      <th>hasStorageRoom</th>\n",
       "      <th>hasGuestRoom</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75523</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>9373</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4313</td>\n",
       "      <td>9005</td>\n",
       "      <td>956</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7559081.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80771</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>39381</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3653</td>\n",
       "      <td>2436</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8085989.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55712</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>34457</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2937</td>\n",
       "      <td>8852</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5574642.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32316</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>27939</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>659</td>\n",
       "      <td>7141</td>\n",
       "      <td>359</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3232561.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70429</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>38045</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1990</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8435</td>\n",
       "      <td>2429</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7055052.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   squareMeters  numberOfRooms  hasYard  hasPool  floors  cityCode  \\\n",
       "0         75523              3        0        1      63      9373   \n",
       "1         80771             39        1        1      98     39381   \n",
       "2         55712             58        0        1      19     34457   \n",
       "3         32316             47        0        0       6     27939   \n",
       "4         70429             19        1        1      90     38045   \n",
       "\n",
       "   cityPartRange  numPrevOwners  made  isNewBuilt  hasStormProtector  \\\n",
       "0              3              8  2005           0                  1   \n",
       "1              8              6  2015           1                  0   \n",
       "2              6              8  2021           0                  0   \n",
       "3             10              4  2012           0                  1   \n",
       "4              3              7  1990           1                  0   \n",
       "\n",
       "   basement  attic  garage  hasStorageRoom  hasGuestRoom      price  \n",
       "0      4313   9005     956               0             7  7559081.5  \n",
       "1      3653   2436     128               1             2  8085989.5  \n",
       "2      2937   8852     135               1             9  5574642.1  \n",
       "3       659   7141     359               0             3  3232561.2  \n",
       "4      8435   2429     292               1             4  7055052.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d3ed1ee-7acf-41cf-a9d0-dab92b05cc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 17 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   squareMeters       10000 non-null  int64  \n",
      " 1   numberOfRooms      10000 non-null  int64  \n",
      " 2   hasYard            10000 non-null  int64  \n",
      " 3   hasPool            10000 non-null  int64  \n",
      " 4   floors             10000 non-null  int64  \n",
      " 5   cityCode           10000 non-null  int64  \n",
      " 6   cityPartRange      10000 non-null  int64  \n",
      " 7   numPrevOwners      10000 non-null  int64  \n",
      " 8   made               10000 non-null  int64  \n",
      " 9   isNewBuilt         10000 non-null  int64  \n",
      " 10  hasStormProtector  10000 non-null  int64  \n",
      " 11  basement           10000 non-null  int64  \n",
      " 12  attic              10000 non-null  int64  \n",
      " 13  garage             10000 non-null  int64  \n",
      " 14  hasStorageRoom     10000 non-null  int64  \n",
      " 15  hasGuestRoom       10000 non-null  int64  \n",
      " 16  price              10000 non-null  float64\n",
      "dtypes: float64(1), int64(16)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0df120f-ddd8-4451-9893-cf30e8542902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на признаки и целевую переменную\n",
    "X = df.drop('price', axis=1)\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7d08591-5e2c-4ea7-a8cf-6e002ba8417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализация данных\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "148b6ca8-9628-4e5b-8079-51ca170603ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на обучающий и тестовый наборы\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bb09c527-9db2-401d-a54e-a31c4975d5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание модели\n",
    "model = tf.keras.Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),  # Явное указание входной формы\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fde9dfcd-07fb-4cb4-8a43-33cb538a20f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Компиляция модели\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8b3cf21-5085-4cf9-a892-d345965e7fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "log_dir = \"logs/fit\"\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cacbc6f1-f3b0-4c22-b94d-cfc5f0a3e0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 32899506110464.0000 - mae: 4964524.0000 - val_loss: 33351419297792.0000 - val_mae: 5017479.0000\n",
      "Epoch 2/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32397686996992.0000 - mae: 4924946.0000 - val_loss: 33334375743488.0000 - val_mae: 5016080.5000\n",
      "Epoch 3/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32929677836288.0000 - mae: 4969577.0000 - val_loss: 33288135639040.0000 - val_mae: 5012367.5000\n",
      "Epoch 4/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32197788565504.0000 - mae: 4920971.0000 - val_loss: 33200107683840.0000 - val_mae: 5005382.5000\n",
      "Epoch 5/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32063791038464.0000 - mae: 4899178.0000 - val_loss: 33061605474304.0000 - val_mae: 4994465.0000\n",
      "Epoch 6/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32976056352768.0000 - mae: 4993674.0000 - val_loss: 32868348723200.0000 - val_mae: 4979277.5000\n",
      "Epoch 7/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31352596463616.0000 - mae: 4821842.5000 - val_loss: 32611254665216.0000 - val_mae: 4959107.5000\n",
      "Epoch 8/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32083713982464.0000 - mae: 4892396.0000 - val_loss: 32287391481856.0000 - val_mae: 4933683.0000\n",
      "Epoch 9/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31930982596608.0000 - mae: 4905439.5000 - val_loss: 31893487616000.0000 - val_mae: 4902725.0000\n",
      "Epoch 10/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 31497006350336.0000 - mae: 4861618.5000 - val_loss: 31429983469568.0000 - val_mae: 4866139.0000\n",
      "Epoch 11/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 30637203390464.0000 - mae: 4788925.5000 - val_loss: 30895455076352.0000 - val_mae: 4823698.5000\n",
      "Epoch 12/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 30235986755584.0000 - mae: 4766344.0000 - val_loss: 30287798992896.0000 - val_mae: 4775114.5000\n",
      "Epoch 13/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28807922712576.0000 - mae: 4637359.0000 - val_loss: 29604733517824.0000 - val_mae: 4720074.0000\n",
      "Epoch 14/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 29258500014080.0000 - mae: 4693419.0000 - val_loss: 28856725536768.0000 - val_mae: 4659133.0000\n",
      "Epoch 15/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27824922558464.0000 - mae: 4548462.0000 - val_loss: 28041560457216.0000 - val_mae: 4591960.5000\n",
      "Epoch 16/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28118498672640.0000 - mae: 4615086.5000 - val_loss: 27169703067648.0000 - val_mae: 4519082.0000\n",
      "Epoch 17/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26203748564992.0000 - mae: 4424178.5000 - val_loss: 26232928337920.0000 - val_mae: 4439671.5000\n",
      "Epoch 18/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25224365998080.0000 - mae: 4332398.0000 - val_loss: 25242195984384.0000 - val_mae: 4354284.0000\n",
      "Epoch 19/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 24119670210560.0000 - mae: 4236282.0000 - val_loss: 24203193483264.0000 - val_mae: 4263097.0000\n",
      "Epoch 20/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23335431831552.0000 - mae: 4176950.7500 - val_loss: 23121419567104.0000 - val_mae: 4166039.0000\n",
      "Epoch 21/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22228152352768.0000 - mae: 4067410.2500 - val_loss: 21997859897344.0000 - val_mae: 4062913.5000\n",
      "Epoch 22/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21277632888832.0000 - mae: 3991812.5000 - val_loss: 20843902009344.0000 - val_mae: 3954258.2500\n",
      "Epoch 23/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20119992401920.0000 - mae: 3880720.5000 - val_loss: 19666609111040.0000 - val_mae: 3840475.5000\n",
      "Epoch 24/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 18561600847872.0000 - mae: 3698329.5000 - val_loss: 18463531728896.0000 - val_mae: 3720906.5000\n",
      "Epoch 25/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 17571663314944.0000 - mae: 3618126.7500 - val_loss: 17248621166592.0000 - val_mae: 3596363.0000\n",
      "Epoch 26/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 16589426524160.0000 - mae: 3516403.7500 - val_loss: 16030781931520.0000 - val_mae: 3467082.5000\n",
      "Epoch 27/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15276804407296.0000 - mae: 3374822.7500 - val_loss: 14810345373696.0000 - val_mae: 3332617.0000\n",
      "Epoch 28/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 14106045186048.0000 - mae: 3234893.0000 - val_loss: 13600916766720.0000 - val_mae: 3193967.2500\n",
      "Epoch 29/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13121747943424.0000 - mae: 3138539.0000 - val_loss: 12412077998080.0000 - val_mae: 3051730.5000\n",
      "Epoch 30/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11797063008256.0000 - mae: 2980161.2500 - val_loss: 11240659222528.0000 - val_mae: 2905091.0000\n",
      "Epoch 31/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10356981235712.0000 - mae: 2768611.0000 - val_loss: 10106493206528.0000 - val_mae: 2755741.0000\n",
      "Epoch 32/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9543750778880.0000 - mae: 2676357.7500 - val_loss: 9010322341888.0000 - val_mae: 2603438.0000\n",
      "Epoch 33/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8360488337408.0000 - mae: 2491659.7500 - val_loss: 7957686779904.0000 - val_mae: 2448346.0000\n",
      "Epoch 34/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7358245765120.0000 - mae: 2345329.7500 - val_loss: 6964044627968.0000 - val_mae: 2292581.0000\n",
      "Epoch 35/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6359015227392.0000 - mae: 2184568.0000 - val_loss: 6021553061888.0000 - val_mae: 2134520.7500\n",
      "Epoch 36/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5467101200384.0000 - mae: 2017801.5000 - val_loss: 5148648669184.0000 - val_mae: 1976732.5000\n",
      "Epoch 37/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4637786636288.0000 - mae: 1869321.5000 - val_loss: 4345302351872.0000 - val_mae: 1819302.5000\n",
      "Epoch 38/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3930093518848.0000 - mae: 1728759.2500 - val_loss: 3616605995008.0000 - val_mae: 1663628.1250\n",
      "Epoch 39/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3269862096896.0000 - mae: 1575129.3750 - val_loss: 2965266497536.0000 - val_mae: 1510573.5000\n",
      "Epoch 40/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2637706035200.0000 - mae: 1421166.3750 - val_loss: 2391698571264.0000 - val_mae: 1361180.0000\n",
      "Epoch 41/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2152742125568.0000 - mae: 1286205.1250 - val_loss: 1896746188800.0000 - val_mae: 1216688.5000\n",
      "Epoch 42/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1686851420160.0000 - mae: 1143004.3750 - val_loss: 1477587894272.0000 - val_mae: 1078031.2500\n",
      "Epoch 43/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1319181746176.0000 - mae: 1013006.5625 - val_loss: 1133440401408.0000 - val_mae: 946784.0625\n",
      "Epoch 44/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1024471465984.0000 - mae: 895798.6875 - val_loss: 857535610880.0000 - val_mae: 823927.1875\n",
      "Epoch 45/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 759770185728.0000 - mae: 769920.5625 - val_loss: 644167172096.0000 - val_mae: 711609.1875\n",
      "Epoch 46/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 574200938496.0000 - mae: 665502.6875 - val_loss: 484300226560.0000 - val_mae: 611737.1875\n",
      "Epoch 47/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 437713043456.0000 - mae: 577182.0000 - val_loss: 369796055040.0000 - val_mae: 526753.8125\n",
      "Epoch 48/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 329181888512.0000 - mae: 492118.0625 - val_loss: 291145646080.0000 - val_mae: 459110.9688\n",
      "Epoch 49/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 260639031296.0000 - mae: 430776.0000 - val_loss: 240211935232.0000 - val_mae: 411009.7500\n",
      "Epoch 50/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 223635947520.0000 - mae: 393292.0625 - val_loss: 207971991552.0000 - val_mae: 380246.9688\n",
      "Epoch 51/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 199829225472.0000 - mae: 371505.3750 - val_loss: 188859924480.0000 - val_mae: 361783.3750\n",
      "Epoch 52/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 183006691328.0000 - mae: 353298.2812 - val_loss: 177839833088.0000 - val_mae: 350399.0938\n",
      "Epoch 53/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 171322753024.0000 - mae: 341518.7500 - val_loss: 171208212480.0000 - val_mae: 342889.2812\n",
      "Epoch 54/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 172150784000.0000 - mae: 339104.1250 - val_loss: 167146422272.0000 - val_mae: 337901.4375\n",
      "Epoch 55/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 167180812288.0000 - mae: 334665.4062 - val_loss: 164449239040.0000 - val_mae: 334146.2500\n",
      "Epoch 56/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 168147173376.0000 - mae: 334456.9688 - val_loss: 162354888704.0000 - val_mae: 331053.8125\n",
      "Epoch 57/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 161097695232.0000 - mae: 325919.5000 - val_loss: 160595427328.0000 - val_mae: 328415.5000\n",
      "Epoch 58/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 153484853248.0000 - mae: 318597.2812 - val_loss: 159067013120.0000 - val_mae: 326078.4062\n",
      "Epoch 59/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 158623367168.0000 - mae: 320930.7500 - val_loss: 157544185856.0000 - val_mae: 323704.2188\n",
      "Epoch 60/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 153507840000.0000 - mae: 316122.6562 - val_loss: 156146794496.0000 - val_mae: 321504.7500\n",
      "Epoch 61/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 158195482624.0000 - mae: 317782.9062 - val_loss: 154780598272.0000 - val_mae: 319503.1875\n",
      "Epoch 62/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 154111836160.0000 - mae: 316093.9375 - val_loss: 153421627392.0000 - val_mae: 317423.5625\n",
      "Epoch 63/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 154744553472.0000 - mae: 315621.4688 - val_loss: 152146968576.0000 - val_mae: 315563.1562\n",
      "Epoch 64/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 153115049984.0000 - mae: 312850.8125 - val_loss: 150751461376.0000 - val_mae: 313622.3750\n",
      "Epoch 65/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 149664890880.0000 - mae: 307874.8125 - val_loss: 149488500736.0000 - val_mae: 311915.0312\n",
      "Epoch 66/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 150158475264.0000 - mae: 307928.3438 - val_loss: 148072218624.0000 - val_mae: 309913.0312\n",
      "Epoch 67/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 146062737408.0000 - mae: 304141.5312 - val_loss: 146751422464.0000 - val_mae: 308283.4688\n",
      "Epoch 68/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 141759479808.0000 - mae: 299255.5625 - val_loss: 145373282304.0000 - val_mae: 306453.1250\n",
      "Epoch 69/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 145360994304.0000 - mae: 302446.5312 - val_loss: 143973400576.0000 - val_mae: 304821.8125\n",
      "Epoch 70/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 147625787392.0000 - mae: 303775.7188 - val_loss: 142580219904.0000 - val_mae: 302947.9688\n",
      "Epoch 71/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 139370283008.0000 - mae: 294965.7188 - val_loss: 141201227776.0000 - val_mae: 301223.9375\n",
      "Epoch 72/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 141632208896.0000 - mae: 294759.0000 - val_loss: 139894521856.0000 - val_mae: 299808.6875\n",
      "Epoch 73/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 138324475904.0000 - mae: 293695.9375 - val_loss: 138328997888.0000 - val_mae: 297894.9688\n",
      "Epoch 74/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 140570738688.0000 - mae: 295601.8438 - val_loss: 136991236096.0000 - val_mae: 296266.9688\n",
      "Epoch 75/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 134710468608.0000 - mae: 290335.2188 - val_loss: 135506616320.0000 - val_mae: 294346.7812\n",
      "Epoch 76/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 136948752384.0000 - mae: 290436.3438 - val_loss: 134109577216.0000 - val_mae: 292631.9375\n",
      "Epoch 77/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 132365082624.0000 - mae: 287087.5938 - val_loss: 132629110784.0000 - val_mae: 290928.0938\n",
      "Epoch 78/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 135250198528.0000 - mae: 290468.5000 - val_loss: 131187015680.0000 - val_mae: 289274.4062\n",
      "Epoch 79/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 127628034048.0000 - mae: 280840.4062 - val_loss: 129611759616.0000 - val_mae: 287364.8750\n",
      "Epoch 80/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 124371181568.0000 - mae: 277936.4062 - val_loss: 128242614272.0000 - val_mae: 285621.7188\n",
      "Epoch 81/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 129286455296.0000 - mae: 282534.7500 - val_loss: 126711955456.0000 - val_mae: 284042.4688\n",
      "Epoch 82/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 123825995776.0000 - mae: 276524.6875 - val_loss: 125268418560.0000 - val_mae: 282578.1250\n",
      "Epoch 83/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 127681036288.0000 - mae: 281535.3125 - val_loss: 123837054976.0000 - val_mae: 280721.1250\n",
      "Epoch 84/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 121937027072.0000 - mae: 275478.0938 - val_loss: 122353917952.0000 - val_mae: 278846.7500\n",
      "Epoch 85/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 125099073536.0000 - mae: 276127.6562 - val_loss: 120901861376.0000 - val_mae: 277269.0312\n",
      "Epoch 86/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 117338030080.0000 - mae: 268434.7188 - val_loss: 119450222592.0000 - val_mae: 275480.6562\n",
      "Epoch 87/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 118399508480.0000 - mae: 268727.0000 - val_loss: 118036463616.0000 - val_mae: 273656.3125\n",
      "Epoch 88/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 113860952064.0000 - mae: 265607.2188 - val_loss: 116529258496.0000 - val_mae: 271925.3438\n",
      "Epoch 89/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 115806986240.0000 - mae: 268161.1875 - val_loss: 115217416192.0000 - val_mae: 270322.8750\n",
      "Epoch 90/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 111859859456.0000 - mae: 262324.8750 - val_loss: 113743757312.0000 - val_mae: 268482.8125\n",
      "Epoch 91/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 113816305664.0000 - mae: 264174.0938 - val_loss: 112427343872.0000 - val_mae: 267116.4688\n",
      "Epoch 92/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 112779649024.0000 - mae: 264726.5312 - val_loss: 110867914752.0000 - val_mae: 264909.6562\n",
      "Epoch 93/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 109085245440.0000 - mae: 257975.2031 - val_loss: 109566394368.0000 - val_mae: 262992.6562\n",
      "Epoch 94/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 108949233664.0000 - mae: 258964.3906 - val_loss: 108171837440.0000 - val_mae: 261861.7188\n",
      "Epoch 95/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 108361474048.0000 - mae: 258463.5312 - val_loss: 106647363584.0000 - val_mae: 259577.1562\n",
      "Epoch 96/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 104169480192.0000 - mae: 253862.7812 - val_loss: 105232613376.0000 - val_mae: 257544.8125\n",
      "Epoch 97/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 99521822720.0000 - mae: 246684.4688 - val_loss: 103876943872.0000 - val_mae: 256269.7188\n",
      "Epoch 98/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 98748186624.0000 - mae: 246359.0625 - val_loss: 102417891328.0000 - val_mae: 254435.3594\n",
      "Epoch 99/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 99007111168.0000 - mae: 243808.6562 - val_loss: 100872257536.0000 - val_mae: 252056.1562\n",
      "Epoch 100/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 101811871744.0000 - mae: 250293.0000 - val_loss: 99509035008.0000 - val_mae: 250172.2344\n"
     ]
    }
   ],
   "source": [
    "# Обучение\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[tensorboard_callback, early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f32751c7-1c3c-4062-8d20-da032d7483f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - loss: 103808073728.0000 - mae: 252733.2031\n"
     ]
    }
   ],
   "source": [
    "# Оценка\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d67675-5905-4c32-9d19-a1ad9f290af0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
